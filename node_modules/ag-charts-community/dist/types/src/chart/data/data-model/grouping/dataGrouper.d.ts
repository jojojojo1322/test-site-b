import type { GroupedData, GroupingFn, UngroupedData } from '../../dataModelTypes';
import type { DataModelContext } from '../dataModelContext';
/**
 * DataGrouper handles grouping of extracted data into groups based on keys.
 *
 * GROUPING RESPONSIBILITIES:
 * - Groups data by key values to aggregate multiple datums
 * - Optimizes batch processing by merging compatible column batches
 * - Maintains group validity tracking across scopes
 * - Supports custom grouping functions for flexible aggregation
 *
 * BATCH MERGING OPTIMIZATION:
 * - Identifies columns that share the same data characteristics
 * - Merges compatible batches to reduce iteration overhead
 * - Can reduce processing iterations by 30-50% for multi-scope datasets
 *
 * Compatibility criteria:
 * - Same keys arrays (by reference)
 * - Same invalidity arrays (by reference)
 * - Scopes can be safely processed together
 */
export declare class DataGrouper<D extends object, K extends keyof D & string> {
    private readonly ctx;
    constructor(ctx: DataModelContext<D, K>);
    /**
     * Groups data by keys or custom grouping function.
     *
     * GROUPED DATA STRUCTURE AND INVARIANTS:
     *
     * When groupsUnique=true (each datum has distinct keys):
     * - groups.length === columns[i].length for all columns
     * - groups[i] corresponds to datum at columns[j][i]
     * - All datumIndices arrays contain [0] (shared memory optimization)
     * - Relative indexing: datumIndices contains offsets from group start
     * - Absolute indexing: groupIndex + relativeDatumIndex gives column position
     *
     * When groupsUnique=false (data is aggregated):
     * - groups.length <= columns[i].length
     * - Multiple datums may map to same group
     * - datumIndices contain actual relative offsets
     *
     * This design optimizes memory usage for high-frequency data updates
     * where each datum typically has unique keys (e.g., time series data).
     */
    groupData(data: UngroupedData<D>, customGroupingFn?: GroupingFn<D>): GroupedData<D>;
    /**
     * Groups and merges column batches for efficient processing.
     *
     * BATCH MERGING OPTIMIZATION:
     * - Identifies columns that share the same data characteristics
     * - Merges compatible batches to reduce iteration overhead
     * - Can reduce processing iterations by 30-50% for multi-scope datasets
     *
     * Compatibility criteria:
     * - Same keys arrays (by reference)
     * - Same invalidity arrays (by reference)
     * - Scopes can be safely processed together
     */
    private groupBatches;
    /**
     * Checks if two column batches can be merged based on shared data characteristics.
     */
    private areBatchesCompatible;
    private mergeCompatibleBatches;
    private findAndMergeCompatibleBatches;
}
